{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_ELASTIC_URL = \"http://192.168.36.98/mytimes/elasticCommentQuery?sort=desc&appKey=TOI,ET&filterCommentStatus=APPROVED,REJECTED,UNVERIFIED\"\n",
    "BATCH_SIZE_PARAM = 250\n",
    "# ITER_BUFFER = 2\n",
    "CSV_FILE_NAME = '/Users/yash.dalmia/elasticComments.csv'\n",
    "DEFAULT_FIELDS = ['C_T']\n",
    "\n",
    "#     field_arr = ['c_id', 'C_T']\n",
    "#     field_arr = ['c_id', 'msid', 'C_T', 'C_D_Minute', 'ED_ID', 'C_APP_RES']\n",
    "    \n",
    "#     field_arr = ['C_T']\n",
    "#     csv_list = [[(x[fieldStr] if (fieldStr in x) else \"\") for fieldStr in field_arr] for x in list_comments if ('C_T' in x)]\n",
    "#     field_arr = ['c_id', 'msid', 'C_T', 'ERO_D', 'F_NAME', 'F_ADD', 'C_D', 'A_ID', 'C_APP_RES']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "startEpoch = None\n",
    "endEpoch = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request, json \n",
    "import math\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getJsonFromUrl(url_param):\n",
    "    with urllib.request.urlopen(url_param) as url:\n",
    "        data = json.loads(url.read().decode())\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createNewCsv(file_path = CSV_FILE_NAME):\n",
    "    with open(file_path, 'w+') as writeFile:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCsvListFromListComments(list_comments, fields_to_take = DEFAULT_FIELDS):\n",
    "    \n",
    "    csv_list = []\n",
    "    for x in list_comments:\n",
    "        if 'C_T' in x:\n",
    "            list1 = []\n",
    "            for fieldStr in fields_to_take:\n",
    "                if \".\" in fieldStr:\n",
    "                    fieldStrArr = fieldStr.split(\".\")\n",
    "                    if fieldStrArr[0] in x and fieldStrArr[1] in x[fieldStrArr[0]]:\n",
    "                        list1.append(x[fieldStrArr[0]][fieldStrArr[1]])\n",
    "                    else:\n",
    "                        list1.append(\"\")\n",
    "                elif fieldStr in x:\n",
    "                    list1.append(x[fieldStr])\n",
    "                else:\n",
    "                    list1.append(\"\")\n",
    "            csv_list.append(list1)\n",
    "            \n",
    "    return csv_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModifiedUrl(url, from_param, size_param, startEpoch=None, endEpoch=None):\n",
    "    result_url = url + \"&from=\" + str(from_param) + \"&size=\" + str(size_param)\n",
    "    if (startEpoch!=None and endEpoch!=None):\n",
    "        result_url = result_url + \"&sDateEpoch=\" + str(startEpoch) + \"&eDateEpoch=\" + str(endEpoch)\n",
    "    return result_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModifiedUrlDate(url, startEpoch=None, endEpoch=None):\n",
    "#     result_url = url + \"&from=\" + str(from_param) + \"&size=\" + str(size_param)\n",
    "    result_url = url\n",
    "    if (startEpoch!=None and endEpoch!=None):\n",
    "        result_url = result_url + \"&sDateEpoch=\" + str(startEpoch) + \"&eDateEpoch=\" + str(endEpoch)\n",
    "    return result_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def appendUrlResultToCsv(url, fields_to_take = DEFAULT_FIELDS, size_param = BATCH_SIZE_PARAM, file_path = CSV_FILE_NAME, force = False, to_download_till = None):\n",
    "    \n",
    "    final_url = getModifiedUrl(url, 0, size_param)\n",
    "    json_raw_response = getJsonFromUrl(final_url)\n",
    "\n",
    "    total_comment_count = json_raw_response['hits']['total']\n",
    "    \n",
    "    ELASTIC_LIMIT = 10000\n",
    "    if (to_download_till != None and to_download_till < total_comment_count):\n",
    "        total_comment_count = to_download_till\n",
    "        \n",
    "    if (total_comment_count > ELASTIC_LIMIT):\n",
    "        print(\"total_comment_count greater than 10000: %d\" %(total_comment_count))\n",
    "        if ~force:\n",
    "            print(\"aborting\")\n",
    "            return\n",
    "        else:\n",
    "            total_comment_count = ELASTIC_LIMIT\n",
    "        \n",
    "    \n",
    "    num_iters = math.ceil(total_comment_count/size_param)\n",
    "#     num_iters = num_iters + ITER_BUFFER\n",
    "\n",
    "    print(\"total_count : %d\" %(total_comment_count))\n",
    "    print(\"num_iters : %d\" %(num_iters))\n",
    "\n",
    "    for iter_val in range(0, num_iters, 1):\n",
    "        print(\"iteration : %d\" %(iter_val))\n",
    "        from_val = iter_val * size_param\n",
    "        final_url = getModifiedUrl(url, from_val, size_param)\n",
    "        json_raw_response = getJsonFromUrl(final_url)\n",
    "        list_comments = [x['_source'] for x in json_raw_response['hits']['hits']]\n",
    "        \n",
    "        csv_list = getCsvListFromListComments(list_comments, fields_to_take)\n",
    "        df_csv = pd.DataFrame(csv_list, columns = fields_to_take)\n",
    "        \n",
    "        with open(file_path, 'a') as f:\n",
    "            df_csv.to_csv(f, index = False, header=f.tell()==0, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_url = \"http://commentmoderator.indiatimes.com/mytimes/elasticCommentQuery?sort=desc&appKey=TOI&filterCommentStatus=APPROVED,REJECTED,UNVERIFIED\"\n",
    "base_url = \"http://commentmoderator.indiatimes.com/mytimes/elasticCommentQuery?sort=desc&appKey=TOI&filterCommentStatus=APPROVED,REJECTED,UNVERIFIED\"\n",
    "\n",
    "csv_file_path = \"data/TOI_1_June.csv\"\n",
    "fields_to_take = ['C_T']\n",
    "\n",
    "batch_write_size = 250\n",
    "\n",
    "createNewCsv(file_path = csv_file_path)\n",
    "\n",
    "NET_END_TIME_EPOCH = 1559413800000\n",
    "NUM_DAYS_IN_ONE_ITER = 0.25\n",
    "NUM_ITERS = 1*4\n",
    "\n",
    "# endEpoch = NET_START_TIME_EPOCH\n",
    "startEpoch = NET_END_TIME_EPOCH\n",
    "\n",
    "for iter_val in range(0, NUM_ITERS, 1):\n",
    "    print(\"\\nIter_val : %d\" %(iter_val))\n",
    "    endEpoch = startEpoch\n",
    "    startEpoch = endEpoch - int(NUM_DAYS_IN_ONE_ITER*24*60*60*1000)\n",
    "    \n",
    "    url = getModifiedUrlDate(base_url, startEpoch, endEpoch)\n",
    "    print(\"url : \" + url)\n",
    "    appendUrlResultToCsv(url, fields_to_take = fields_to_take, size_param = batch_write_size, file_path = csv_file_path)\n",
    "\n",
    "print(\"\\nnet startEpoch : \", startEpoch)\n",
    "print(\"net endEpoch : \", NET_END_TIME_EPOCH)\n",
    "print(\"csv written to %s\"%(csv_file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# url = \"http://commentmoderator.indiatimes.com/mytimes/elasticCommentQuery?sort=desc&appKey=NBTO&filterCommentStatus=APPROVED,REJECTED,UNVERIFIED&sDate=24%2F4%2F2019&eDate=24%2F4%2F2019\"\n",
    "url = \"http://commentmoderator.indiatimes.com/mytimes/elasticCommentQuery?sort=desc&filterCommentStatus=APPROVED,REJECTED,UNVERIFIED&sDateEpoch=1548412448000&eDateEpoch=1556188448000&appKey=TOI&queryString=_exists_:SPAM_VAL%20AND%20SPAM_VAL.isSpam:false&multiActorId=6179270,665245713,14219596,6267354,665046059,549930791,548178454,668244979,663707220,22541448,2366863,2589915,655718924,526173678,659669241,103473849,2515704\"\n",
    "from_param = 0\n",
    "size_param = 50\n",
    "# print(getModifiedUrl(url, from_param, size_param))\n",
    "csv_file_path = \"data/most_abusive_TOI_last_90_days_25April.csv\"\n",
    "fields_to_take = ['c_id', 'C_T', 'SPAM_VAL.round_prob']\n",
    "\n",
    "createNewCsv(file_path = csv_file_path)\n",
    "\n",
    "appendUrlResultToCsv(url, fields_to_take = fields_to_take, size_param = 250, file_path = csv_file_path)\n",
    "print('saved file at {}'.format(csv_file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_file_path = \"/Users/yash.dalmia/NBT_spam_13-19June.csv\"\n",
    "# createNewCsv(file_path = csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_count : 71\n",
      "num_iters : 1\n",
      "iteration : 0\n"
     ]
    }
   ],
   "source": [
    "# base_url = \"http://commentmoderator.indiatimes.com/mytimes/elasticCommentQuery?sort=desc&appKey=NBTO&filterCommentStatus=APPROVED,REJECTED,UNVERIFIED&sDate=13%2F6%2F2019&rejectionType=ML_PROCESS\"\n",
    "# fields_to_take = ['C_T', 'C_D']\n",
    "# batch_write_size = 150\n",
    "# appendUrlResultToCsv(base_url, fields_to_take = fields_to_take, size_param = batch_write_size, file_path = csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# get_time = lambda x : time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(x/1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_r = pd.read_csv(csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_r['time'] = df_r['C_D'].apply(get_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_time(1560924551196)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_r = df_r.drop(columns=['C_D'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_r.rename(index=str, columns={'C_T': 'Comment Text', 'time': 'Time'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_r.to_csv(csv_file_path, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
